{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rhitabrat/MAMI/blob/main/Text%20plus%20Visual%20Embeddings/image_text_from_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEbvOBvNzSJP"
      },
      "source": [
        "Generate baseline for image plus text data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tf-models-official"
      ],
      "metadata": {
        "id": "vsyUbjl6kn8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U tensorflow-text"
      ],
      "metadata": {
        "id": "OnGUq5WrkoBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6_QQWKnczWhi",
        "outputId": "87352170-c44f-4b4b-ab35-6a2b46376ca6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "requires the same folder:\n",
        "- script evaluation\n",
        "-folder 'ref' with truth.txt\n",
        "-folder 'TRAINING' with images\n",
        "'''\n",
        "\n",
        "# import evaluation\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow.keras.layers as layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras import regularizers\n",
        "import os\n",
        "import gc\n",
        "import shutil \n"
      ],
      "metadata": {
        "id": "uTC8UnjAzX0S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.disable_eager_execution()"
      ],
      "metadata": {
        "id": "txUGNSnQZCkh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paths\n",
        "csv_path_test = '/content/drive/MyDrive/PSU/NLP Lab/MAMI/TEST/CSV/Test.csv'\n",
        "csv_path_train = '/content/drive/MyDrive/PSU/NLP Lab/MAMI/TRAIN/CSVs/training_original.csv'\n",
        "image_path = '/content/drive/MyDrive/PSU/NLP Lab/MAMI/TRAIN/Images'\n",
        "\n",
        "\n",
        "def loadImage(image_path):\n",
        "    try:\n",
        "        return load_img(image_path, target_size=(image_size, image_size))\n",
        "    except:\n",
        "        image_path = image_path.replace('png', 'jpg')\n",
        "        return load_img(image_path, target_size=(image_size, image_size))\n",
        "\n",
        "# if not os.path.exists('./ImageTextModel'):\n",
        "    # os.makedirs('./ImageTextModel')\n",
        "\n",
        "if not os.path.exists('/content/drive/MyDrive/PSU/NLP Lab/MAMI/Saved Models/ImageTextModel'):\n",
        "    os.makedirs('/content/drive/MyDrive/PSU/NLP Lab/MAMI/Saved Models/ImageTextModel')\n",
        "    \n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "image_size = 224\n",
        "embed_size = 768 #according to USE\n",
        "threshold = 0.5\n",
        "\n",
        "# #Universal Sentence Encoder\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed\"\n",
        "embed = hub.Module(module_url)"
      ],
      "metadata": {
        "id": "6biQ6eIzzeCs"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test"
      ],
      "metadata": {
        "id": "aPh0udixoO1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_text as text\n",
        "from official.nlp import optimization\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "qciXHJMpoSZZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_model = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ],
      "metadata": {
        "id": "uLisjez5oSbj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HmjcEqlj1Fga"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#_______________________________Load Train Data_______________________________\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(csv_path_train, usecols=['file_name', 'misogynous', 'Text Transcription'], sep='\\t')\n",
        "path = image_path+'/'\n",
        "\n",
        "train_df['image_path'] = path + train_df['file_name']\n",
        "\n",
        "# Universal Sentence Encoder (USE)\n",
        "'''\n",
        "Split the dataset to avoid hitting the USE call limit\n",
        "an error occurs if the 47900 steps are reached\n",
        "'''\n",
        "dfs = np.array_split(train_df, 10)\n",
        "train_df['USE'] = None\n",
        "text_embeddings=[]\n",
        "with tf.compat.v1.Session() as session:\n",
        "    session.run([tf.compat.v1.global_variables_initializer(), tf.compat.v1.tables_initializer()])\n",
        "   \n",
        "    for x in dfs:\n",
        "      x_data_matches = pd.Series([])\n",
        "    #   text_embedding = session.run(embed(list(x['Text Transcription'])))\n",
        "      preprocess = bert_preprocess_model(list(x['Text Transcription']))\n",
        "      text_embedding = session.run(bert_model(preprocess)['pooled_output'])\n",
        "      \n",
        "      text_embeddings = text_embeddings + np.array(text_embedding).tolist()\n",
        "      \n",
        "train_df['USE'] = text_embeddings\n"
      ],
      "metadata": {
        "id": "lDga2GKV3gbB",
        "outputId": "422d8e82-ad8e-483a-9067-577187e1ebb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"/content/drive/MyDrive/PSU/NLP Lab/MAMI/Saved Items/trained_bert_2.csv\", index=False)"
      ],
      "metadata": {
        "id": "RJnJIQeR3gjm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #_______________________________Load Train Data_______________________________\n",
        "# train_df = pd.read_csv(csv_path_train, usecols=['file_name', 'misogynous', 'Text Transcription'], sep='\\t')\n",
        "# path = image_path+'/'\n",
        "\n",
        "# train_df['image_path'] = path + train_df['file_name']\n",
        "\n",
        "# # Universal Sentence Encoder (USE)\n",
        "# '''\n",
        "# Split the dataset to avoid hitting the USE call limit\n",
        "# an error occurs if the 47900 steps are reached\n",
        "# '''\n",
        "# dfs = np.array_split(train_df, 10)\n",
        "# train_df['USE'] = None\n",
        "# text_embeddings=[]\n",
        "# with tf.compat.v1.Session() as session:\n",
        "#     session.run([tf.compat.v1.global_variables_initializer(), tf.compat.v1.tables_initializer()])\n",
        "   \n",
        "#     for x in dfs:\n",
        "#       x_data_matches = pd.Series([])\n",
        "#       text_embedding = session.run(embed(list(x['Text Transcription'])))\n",
        "#       text_embeddings = text_embeddings + np.array(text_embedding).tolist()\n",
        "      \n",
        "# train_df['USE'] = text_embeddings\n",
        "\n",
        "#load images\n",
        "train_df['image'] = None\n",
        "train_df['image'] = train_df['image_path'].apply(lambda x: img_to_array(loadImage(x)))        \n",
        "\n",
        "#division and processing of data as input to the model\n",
        "X_train = train_df[['file_name', 'USE', 'image']]\n",
        "y_train = train_df['misogynous']\n",
        "\n",
        "#text\n",
        "tmp = []\n",
        "for value in X_train['USE']:\n",
        "    tmp.append([value])  \n",
        "tX_train = np.array(tmp)\n",
        "\n",
        "#images\n",
        "tmp = []\n",
        "for value in X_train['image']:\n",
        "  tmp.append(value) \n",
        "iX_train = np.array(tmp)\n",
        "\n",
        "#misogynous label\n",
        "tmp = []\n",
        "for value in y_train:\n",
        "    tmp.append([value])  \n",
        "y_train = np.array(tmp)\n",
        "\n",
        "#clear memory\n",
        "del train_df\n",
        "del dfs\n",
        "del text_embedding\n",
        "del text_embeddings\n",
        "\n",
        "gc.collect()\n",
        "\n"
      ],
      "metadata": {
        "id": "83cnwG2BzeEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image"
      ],
      "metadata": {
        "id": "UqN3WVuymLBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#_______________________________IMAGE MODEL_______________________________\n",
        "l2_strength = 1e-5\n",
        "\n",
        "input_image = layers.Input(shape=(image_size,image_size,3))\n",
        "vgg_model = VGG16(input_tensor = input_image, weights = 'imagenet', include_top=False)\n",
        "\n",
        "for layer in vgg_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = vgg_model.output\n",
        "x = layers.Flatten(input_shape=vgg_model.output_shape[1:])(x)\n",
        "x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(l2_strength))(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l2_strength))(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "image_model = Model(vgg_model.input, x)\n",
        "\n",
        "image_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "image_model.summary()\n",
        "\n",
        "history = image_model.fit(iX_train, \n",
        "                    y_train,\n",
        "                    validation_split=0.1,\n",
        "                    epochs= 30,\n",
        "                    batch_size=batch_size,\n",
        "                    #verbose=0,\n",
        "                    )\n",
        "                    \n",
        "# image_model.save('/content/drive/MyDrive/PSU/NLP Lab/MAMI/Saved Models/ImageTextModel/image_model.h5')"
      ],
      "metadata": {
        "id": "NSthHOR5zeGt",
        "outputId": "c4580175-e301-40ed-b04a-b5ba3dcf9721",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 256)               6422784   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,153,985\n",
            "Trainable params: 6,439,297\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/30\n",
            "9000/9000 [==============================] - ETA: 0s - loss: 3.4260 - accuracy: 0.5660"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9000/9000 [==============================] - 35s 4ms/sample - loss: 3.4260 - accuracy: 0.5660 - val_loss: 0.6776 - val_accuracy: 0.5640\n",
            "Epoch 2/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.8286 - accuracy: 0.5932 - val_loss: 0.6623 - val_accuracy: 0.6600\n",
            "Epoch 3/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.6957 - accuracy: 0.6408 - val_loss: 0.7802 - val_accuracy: 0.6550\n",
            "Epoch 4/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.7171 - accuracy: 0.6546 - val_loss: 0.6298 - val_accuracy: 0.6690\n",
            "Epoch 5/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.7090 - accuracy: 0.6609 - val_loss: 0.6176 - val_accuracy: 0.6930\n",
            "Epoch 6/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.6525 - accuracy: 0.6777 - val_loss: 0.6475 - val_accuracy: 0.6630\n",
            "Epoch 7/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.6487 - accuracy: 0.6873 - val_loss: 0.6131 - val_accuracy: 0.6930\n",
            "Epoch 8/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.6181 - accuracy: 0.6920 - val_loss: 0.6456 - val_accuracy: 0.6820\n",
            "Epoch 9/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.5731 - accuracy: 0.6887 - val_loss: 0.7005 - val_accuracy: 0.6980\n",
            "Epoch 10/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.5997 - accuracy: 0.7066 - val_loss: 0.6760 - val_accuracy: 0.6800\n",
            "Epoch 11/30\n",
            "9000/9000 [==============================] - 22s 2ms/sample - loss: 0.5615 - accuracy: 0.7087 - val_loss: 0.6605 - val_accuracy: 0.6960\n",
            "Epoch 12/30\n",
            "9000/9000 [==============================] - 22s 2ms/sample - loss: 0.5642 - accuracy: 0.7082 - val_loss: 0.6875 - val_accuracy: 0.7060\n",
            "Epoch 13/30\n",
            "9000/9000 [==============================] - 22s 2ms/sample - loss: 0.5453 - accuracy: 0.7154 - val_loss: 0.7191 - val_accuracy: 0.6890\n",
            "Epoch 14/30\n",
            "9000/9000 [==============================] - 22s 2ms/sample - loss: 0.5472 - accuracy: 0.7176 - val_loss: 0.6455 - val_accuracy: 0.6940\n",
            "Epoch 15/30\n",
            "9000/9000 [==============================] - 22s 2ms/sample - loss: 0.5177 - accuracy: 0.7248 - val_loss: 0.7247 - val_accuracy: 0.6920\n",
            "Epoch 16/30\n",
            "9000/9000 [==============================] - 22s 2ms/sample - loss: 0.5217 - accuracy: 0.7236 - val_loss: 0.8048 - val_accuracy: 0.6900\n",
            "Epoch 17/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.5339 - accuracy: 0.7242 - val_loss: 0.7228 - val_accuracy: 0.6940\n",
            "Epoch 18/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.5221 - accuracy: 0.7296 - val_loss: 0.7812 - val_accuracy: 0.6970\n",
            "Epoch 19/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.5204 - accuracy: 0.7248 - val_loss: 0.7462 - val_accuracy: 0.6810\n",
            "Epoch 20/30\n",
            "9000/9000 [==============================] - 22s 2ms/sample - loss: 0.5083 - accuracy: 0.7320 - val_loss: 0.9022 - val_accuracy: 0.6840\n",
            "Epoch 21/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.5291 - accuracy: 0.7363 - val_loss: 0.7440 - val_accuracy: 0.7020\n",
            "Epoch 22/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.5248 - accuracy: 0.7433 - val_loss: 0.8131 - val_accuracy: 0.6970\n",
            "Epoch 23/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.5164 - accuracy: 0.7360 - val_loss: 0.7551 - val_accuracy: 0.7060\n",
            "Epoch 24/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.4847 - accuracy: 0.7459 - val_loss: 0.6840 - val_accuracy: 0.7010\n",
            "Epoch 25/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.4917 - accuracy: 0.7514 - val_loss: 0.8444 - val_accuracy: 0.7070\n",
            "Epoch 26/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.5048 - accuracy: 0.7442 - val_loss: 0.8082 - val_accuracy: 0.6950\n",
            "Epoch 27/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.5009 - accuracy: 0.7537 - val_loss: 0.8954 - val_accuracy: 0.7000\n",
            "Epoch 28/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.5026 - accuracy: 0.7494 - val_loss: 0.8872 - val_accuracy: 0.7070\n",
            "Epoch 29/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.4796 - accuracy: 0.7676 - val_loss: 0.8034 - val_accuracy: 0.7100\n",
            "Epoch 30/30\n",
            "9000/9000 [==============================] - 21s 2ms/sample - loss: 0.4905 - accuracy: 0.7540 - val_loss: 0.9609 - val_accuracy: 0.7040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text"
      ],
      "metadata": {
        "id": "t9Fh-HhimNkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#_______________________________TEXT MODEL_______________________________\n",
        "input_text = layers.Input(shape=(1, embed_size))\n",
        "l = layers.Dense(1, activation='sigmoid')(input_text)\n",
        "text_model = Model(inputs=[input_text], outputs=l)\n",
        "text_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "text_model.summary()\n",
        "\n",
        "history = text_model.fit(tX_train, \n",
        "                    y_train,\n",
        "                    validation_split=0.1,\n",
        "                    epochs= 30,\n",
        "                    batch_size=batch_size,\n",
        "                    #verbose=0\n",
        "                    )\n",
        "\n",
        "text_model.save('/content/drive/MyDrive/PSU/NLP Lab/MAMI/Saved Models/ImageTextModel/text_model.h5')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9Qz9JD9DzeJx",
        "outputId": "4dd701ad-14d9-4391-e258-ac06adbd2485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1, 512)]          0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1, 1)              513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 513\n",
            "Trainable params: 513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/30\n",
            "8896/9000 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5027"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9000/9000 [==============================] - 4s 453us/sample - loss: 0.6933 - accuracy: 0.5027 - val_loss: 0.6941 - val_accuracy: 0.4833\n",
            "Epoch 2/30\n",
            "9000/9000 [==============================] - 1s 69us/sample - loss: 0.6933 - accuracy: 0.5030 - val_loss: 0.6945 - val_accuracy: 0.4816\n",
            "Epoch 3/30\n",
            "9000/9000 [==============================] - 1s 66us/sample - loss: 0.6933 - accuracy: 0.5026 - val_loss: 0.6931 - val_accuracy: 0.5038\n",
            "Epoch 4/30\n",
            "9000/9000 [==============================] - 1s 60us/sample - loss: 0.6932 - accuracy: 0.5041 - val_loss: 0.6939 - val_accuracy: 0.4903\n",
            "Epoch 5/30\n",
            "9000/9000 [==============================] - 1s 63us/sample - loss: 0.6932 - accuracy: 0.5044 - val_loss: 0.6955 - val_accuracy: 0.4794\n",
            "Epoch 6/30\n",
            "9000/9000 [==============================] - 1s 62us/sample - loss: 0.6933 - accuracy: 0.5028 - val_loss: 0.6938 - val_accuracy: 0.4895\n",
            "Epoch 7/30\n",
            "9000/9000 [==============================] - 1s 60us/sample - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6942 - val_accuracy: 0.4904\n",
            "Epoch 8/30\n",
            "9000/9000 [==============================] - 1s 60us/sample - loss: 0.6931 - accuracy: 0.5058 - val_loss: 0.6945 - val_accuracy: 0.4860\n",
            "Epoch 9/30\n",
            "9000/9000 [==============================] - 1s 60us/sample - loss: 0.6933 - accuracy: 0.5039 - val_loss: 0.6936 - val_accuracy: 0.4945\n",
            "Epoch 10/30\n",
            "9000/9000 [==============================] - 1s 61us/sample - loss: 0.6931 - accuracy: 0.5054 - val_loss: 0.6962 - val_accuracy: 0.4740\n",
            "Epoch 11/30\n",
            "9000/9000 [==============================] - 1s 63us/sample - loss: 0.6932 - accuracy: 0.5061 - val_loss: 0.6966 - val_accuracy: 0.4723\n",
            "Epoch 12/30\n",
            "9000/9000 [==============================] - 1s 60us/sample - loss: 0.6933 - accuracy: 0.5047 - val_loss: 0.6948 - val_accuracy: 0.4839\n",
            "Epoch 13/30\n",
            "9000/9000 [==============================] - 1s 63us/sample - loss: 0.6932 - accuracy: 0.5061 - val_loss: 0.6931 - val_accuracy: 0.5060\n",
            "Epoch 14/30\n",
            "9000/9000 [==============================] - 1s 64us/sample - loss: 0.6932 - accuracy: 0.5066 - val_loss: 0.6949 - val_accuracy: 0.4816\n",
            "Epoch 15/30\n",
            "9000/9000 [==============================] - 1s 64us/sample - loss: 0.6932 - accuracy: 0.5062 - val_loss: 0.6935 - val_accuracy: 0.4976\n",
            "Epoch 16/30\n",
            "9000/9000 [==============================] - 1s 64us/sample - loss: 0.6932 - accuracy: 0.5051 - val_loss: 0.6932 - val_accuracy: 0.5004\n",
            "Epoch 17/30\n",
            "9000/9000 [==============================] - 1s 61us/sample - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6945 - val_accuracy: 0.4861\n",
            "Epoch 18/30\n",
            "9000/9000 [==============================] - 1s 62us/sample - loss: 0.6933 - accuracy: 0.5038 - val_loss: 0.6944 - val_accuracy: 0.4851\n",
            "Epoch 19/30\n",
            "9000/9000 [==============================] - 1s 61us/sample - loss: 0.6932 - accuracy: 0.5032 - val_loss: 0.6944 - val_accuracy: 0.4842\n",
            "Epoch 20/30\n",
            "9000/9000 [==============================] - 1s 62us/sample - loss: 0.6932 - accuracy: 0.5055 - val_loss: 0.6957 - val_accuracy: 0.4747\n",
            "Epoch 21/30\n",
            "9000/9000 [==============================] - 1s 64us/sample - loss: 0.6932 - accuracy: 0.5046 - val_loss: 0.6923 - val_accuracy: 0.5209\n",
            "Epoch 22/30\n",
            "9000/9000 [==============================] - 1s 65us/sample - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6920 - val_accuracy: 0.5219\n",
            "Epoch 23/30\n",
            "9000/9000 [==============================] - 1s 65us/sample - loss: 0.6934 - accuracy: 0.5028 - val_loss: 0.6922 - val_accuracy: 0.5231\n",
            "Epoch 24/30\n",
            "9000/9000 [==============================] - 1s 66us/sample - loss: 0.6932 - accuracy: 0.5065 - val_loss: 0.6942 - val_accuracy: 0.4908\n",
            "Epoch 25/30\n",
            "9000/9000 [==============================] - 1s 62us/sample - loss: 0.6931 - accuracy: 0.5058 - val_loss: 0.6955 - val_accuracy: 0.4750\n",
            "Epoch 26/30\n",
            "9000/9000 [==============================] - 1s 60us/sample - loss: 0.6931 - accuracy: 0.5068 - val_loss: 0.6956 - val_accuracy: 0.4789\n",
            "Epoch 27/30\n",
            "9000/9000 [==============================] - 1s 63us/sample - loss: 0.6931 - accuracy: 0.5066 - val_loss: 0.6945 - val_accuracy: 0.4808\n",
            "Epoch 28/30\n",
            "9000/9000 [==============================] - 1s 70us/sample - loss: 0.6932 - accuracy: 0.5054 - val_loss: 0.6949 - val_accuracy: 0.4833\n",
            "Epoch 29/30\n",
            "9000/9000 [==============================] - 1s 60us/sample - loss: 0.6933 - accuracy: 0.5056 - val_loss: 0.6918 - val_accuracy: 0.5265\n",
            "Epoch 30/30\n",
            "9000/9000 [==============================] - 1s 63us/sample - loss: 0.6933 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.4867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = image_model.layers[len(image_model.layers)-2].output\n",
        "reshape = layers.Reshape((1, image_model.layers[len(image_model.layers)-2].output_shape[1]), name='predictions')(image)\n",
        "text = text_model.layers[0].output\n",
        "\n",
        "input = tf.keras.layers.Concatenate(axis=-1)([text, reshape])\n",
        "\n",
        "l = layers.Dense(1, activation='sigmoid')(input)\n",
        "model = Model(inputs=[input_text, input_image], outputs=[l])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "YUHcHY98SWHL",
        "outputId": "718ad2cc-81e8-40f9-cad9-771ec02481d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 224, 224, 64  1792        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 224, 224, 64  36928       ['block1_conv1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, 112, 112, 64  0           ['block1_conv2[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)          (None, 112, 112, 12  73856       ['block1_pool[0][0]']            \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)          (None, 112, 112, 12  147584      ['block2_conv1[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 56, 56, 128)  0           ['block2_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)          (None, 56, 56, 256)  295168      ['block2_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 28, 28, 256)  0           ['block3_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)          (None, 28, 28, 512)  1180160     ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 14, 14, 512)  0           ['block4_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv1 (Conv2D)          (None, 14, 14, 512)  2359808     ['block4_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block5_conv2 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv3 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block5_pool (MaxPooling2D)     (None, 7, 7, 512)    0           ['block5_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 25088)        0           ['block5_pool[0][0]']            \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 256)          6422784     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 256)          0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 64)           16448       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 1, 512)]     0           []                               \n",
            "                                                                                                  \n",
            " predictions (Reshape)          (None, 1, 64)        0           ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 1, 576)       0           ['input_2[0][0]',                \n",
            "                                                                  'predictions[0][0]']            \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 1, 1)         577         ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,154,497\n",
            "Trainable params: 6,439,809\n",
            "Non-trainable params: 14,714,688\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g_t3z4A1Shq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-uI-t1CD9kUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "84yJe3lm9kWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_image = layers.Input(shape=(image_size,image_size,3))\n",
        "# vgg_model = VGG16(input_tensor = input_image, weights = 'imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "s42i2B5J9kZV",
        "outputId": "14c7e239-a811-4e7b-dec2-9d4a04eaf379",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# txt_model = tf.keras.models.load_model('/content/drive/MyDrive/PSU/NLP Lab/MAMI/Saved Models/ImageTextModel/text_model.h5')\n",
        "# # txt_model.summary()\n",
        "# txt_model.layers[0].output"
      ],
      "metadata": {
        "id": "sRdqSyFW9kbV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load image_model from dir\n",
        "image_model = tf.keras.models.load_model('/content/drive/MyDrive/PSU/NLP Lab/MAMI/Saved Models/ImageTextModel/image_model.h5')\n",
        "# image_model.summary()"
      ],
      "metadata": {
        "id": "aZG7s2z1oKzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#_______________________________IMAGE-TEXT MODEL_______________________________\n",
        "image = image_model.layers[len(image_model.layers)-2].output\n",
        "reshape = layers.Reshape((1, image_model.layers[len(image_model.layers)-2].output_shape[1]), name='predictions')(image)\n",
        "text = text_model.layers[0].output\n",
        "\n",
        "input = tf.keras.layers.Concatenate(axis=-1)([text, reshape])\n",
        "\n",
        "l = layers.Dense(1, activation='sigmoid')(input)\n",
        "model = Model(inputs=[input_text, input_image], outputs=[l])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model.save('/content/drive/MyDrive/PSU/NLP Lab/MAMI/Saved Models/ImageTextModel/image_text_model.h5')\n",
        "tf.keras.utils.plot_model(model, \"/content/drive/MyDrive/PSU/NLP Lab/MAMI/Saved Models/ImageTextModel/model.png\", show_shapes=True)"
      ],
      "metadata": {
        "id": "9bFHxXaozeN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RdzbDDGxU8nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#_______________________________Load Test Data_______________________________\n",
        "#clear memory\n",
        "# del X_train\n",
        "# del y_train\n",
        "# del iX_train\n",
        "# del tX_train\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "# paths\n",
        "csv_path_test = '/content/drive/MyDrive/PSU/NLP Lab/MAMI/TEST/CSV/Test.csv'\n",
        "image_path = '/content/drive/MyDrive/PSU/NLP Lab/MAMI/TEST/Images'\n",
        "\n",
        "#load data\n",
        "test_df = pd.read_csv(csv_path_test, sep='\\t')\n",
        "path = image_path+'/'\n",
        "test_df['image_path'] = path + test_df['file_name']\n",
        "\n",
        "# Universal Sentence Encoder (USE)\n",
        "'''\n",
        "Split the dataset to avoid hitting the USE call limit\n",
        "an error occurs if the 47900 steps are reached\n",
        "'''\n",
        "# dfs = np.array_split(test_df, 10)\n",
        "# test_df['USE'] = None\n",
        "# text_embeddings=[]\n",
        "# with tf.compat.v1.Session() as session:\n",
        "#     session.run([tf.compat.v1.global_variables_initializer(), tf.compat.v1.tables_initializer()])\n",
        "   \n",
        "#     for x in dfs:\n",
        "#       x_data_matches = pd.Series([])\n",
        "#     #   text_embedding = session.run(embed(list(x['Text Transcription'])))\n",
        "#       preprocess = bert_preprocess_model(list(x['Text Transcription']))\n",
        "#       text_embedding = session.run(bert_model(preprocess)['pooled_output'])\n",
        "      \n",
        "#       text_embeddings = text_embeddings + np.array(text_embedding).tolist()\n",
        "      \n",
        "# test_df['USE'] = text_embeddings\n",
        "\n",
        "dfs = np.array_split(test_df, 10)\n",
        "test_df['USE'] = None\n",
        "text_embeddings=[]\n",
        "with tf.compat.v1.Session() as session:\n",
        "    session.run([tf.compat.v1.global_variables_initializer(), tf.compat.v1.tables_initializer()])\n",
        "   \n",
        "    for x in dfs:\n",
        "      x_data_matches = pd.Series([])\n",
        "      text_embedding = session.run(embed(list(x['Text Transcription'])))\n",
        "      text_embeddings = text_embeddings + np.array(text_embedding).tolist()\n",
        "test_df['USE'] = text_embeddings\n",
        "\n",
        "#Load images\n",
        "test_df['image'] = None\n",
        "test_df['image'] = test_df['image_path'].apply(lambda x: img_to_array(loadImage(x)))        \n",
        "\n",
        "#division and processing of data as input to the model\n",
        "X_test = test_df[['file_name', 'USE', 'image']]\n",
        "\n",
        "#Text\n",
        "tmp = []\n",
        "for value in X_test['USE']:\n",
        "    tmp.append([value])  \n",
        "tX_test = np.array(tmp)\n",
        "\n",
        "\n",
        "#images\n",
        "tmp = []\n",
        "for value in X_test['image']:\n",
        "    tmp.append(value)  \n",
        "iX_test = np.array(tmp)\n",
        "\n",
        "#clear memory\n",
        "del tmp\n",
        "del dfs\n",
        "del text_embedding\n",
        "del text_embeddings\n",
        "\n",
        "gc.collect()\n",
        "\n"
      ],
      "metadata": {
        "id": "rvpHEKnlzePt",
        "outputId": "c636fc38-73db-46ec-e4f6-b0b1a13ca181",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_df.to_csv(\"/content/drive/MyDrive/PSU/NLP Lab/MAMI/Saved Items/trained_bert_test_1.csv\", index=False)"
      ],
      "metadata": {
        "id": "zCCpryrdndWf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VEkwH_bFnjE4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GM13izPjnjJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#_______________________________PREDICTION_______________________________\n",
        "predictions = model.predict([tX_test, iX_test], batch_size=batch_size)\n",
        "predictions = predictions.reshape(predictions.shape[0])\n",
        "pred = predictions > threshold\n",
        "pred = list(map(int, pred)) #true/false to 1/0\n",
        "\n",
        "predictions_db = pd.DataFrame(data=test_df['file_name'])\n",
        "predictions_db['misogynist'] = pred\n"
      ],
      "metadata": {
        "id": "WA00s39mzeSY",
        "outputId": "a62be7cf-53fc-4b21-ec81-10f041f091e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_db.to_csv(\"/content/drive/MyDrive/PSU/NLP Lab/MAMI/result.csv\", index=False)\n",
        "predictions_db"
      ],
      "metadata": {
        "id": "s44dE2ejlGhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluation\n",
        "\n",
        "#_______________________________EVALUATION_______________________________\n",
        "if not os.path.exists('./res'):\n",
        "    os.makedirs('./res')\n",
        "\n",
        "predictions_db.to_csv('./res/answer.txt', index=False, sep='\\t', header=False)\n",
        "evaluation.main(['','./', '/content/drive/MyDrive/PSU/NLP Lab/MAMI/Saved Models/ImageTextModel/'])\n",
        "#move res folder to ImageTextModel folder\n",
        "shutil.move('./res/', '/content/drive/MyDrive/PSU/NLP Lab/MAMI/Saved Models/ImageTextModel/res/')\n"
      ],
      "metadata": {
        "id": "b9A5q9z5zeUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import f1_score\n",
        "\n",
        "# f1_score(test_df['misogynous'], predictions_db['misogynist'], average='micro')"
      ],
      "metadata": {
        "id": "NwALGpOfzeWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KpjxNJVxzeZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eOpvAsrnzea6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OJCzqBeszefE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ADZoBJPhzehB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VTP-1hmqzekj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "image_text_baseline.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}